{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e2ab8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set these variables according to your setup for the code below to use.\n",
    "tesseract_executable = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15578f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all necessary libraries\n",
    "import torch \n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pytesseract\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from PIL import Image\n",
    "from re import compile\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46811b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = tesseract_executable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "925969bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Iliyan Tashinov/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2023-6-20 Python-3.11.2 torch-2.0.0+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path = 'weights/epochs_100/last.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f83a51f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extraction(gray_frame,detections,frame_count):\n",
    "    \n",
    "    frame_count = frame_count\n",
    "    plate_format = re.compile('^[a-zA-Z]{2}[0-9]{4}[a-zA-Z]{2}$')\n",
    "    plate_format1 = re.compile('^[a-zA-Z]{1}[0-9]{4}[a-zA-Z]{2}$')\n",
    "    data = detections\n",
    "    crop = get_crop(gray_frame,data)\n",
    "    crop_contoured = get_contour1(crop)\n",
    "    license_plate = extract_license(crop_contoured,frame_count)\n",
    "    print(license_plate)\n",
    "    \n",
    "    if plate_format.match(license_plate) is not None or plate_format1.match(license_plate) is not None:\n",
    "    \n",
    "        return crop_contoured,license_plate\n",
    "    \n",
    "    license_plate = \"N/A\"\n",
    "    return crop_contoured,license_plate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7c5e198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crop(frame,detections):\n",
    "    \n",
    "    a,b = get_frameProportions(frame)\n",
    "    data = detections\n",
    "    crop = frame[int(detections[1]*a):int(detections[3]*a),\n",
    "                 int(detections[0]*b):int(detections[2]*b)]\n",
    "    cv2.imwrite(os.path.join('crop' ,'detection.jpg'), crop)\n",
    "    return crop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5aee24d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contour1(crop):\n",
    "\n",
    "    threshold = cv2.threshold(crop, 85, 255,cv2.THRESH_BINARY)[1]\n",
    "    crop_contoured = cv2.bitwise_not(threshold)\n",
    "    \n",
    "    \n",
    "    return crop_contoured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdffb44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contour2(crop):\n",
    "\n",
    "    ret, thresh = cv2.threshold(crop, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)\n",
    "    img = cv2.blur(thresh, ksize=(1,1))\n",
    "    kernelmatrix = np.ones((2, 1), np.uint8)\n",
    "    blurred = cv2.dilate(img, kernelmatrix, iterations=1)\n",
    "    ret, resultimage = cv2.threshold(thresh, 0, 255, cv2.THRESH_TRIANGLE)\n",
    "    crop_contoured = cv2.erode(resultimage, kernelmatrix, iterations=2)\n",
    "    \n",
    "    \n",
    "    return crop_contoured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe558790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_license(crop_contoured,frame_count):\n",
    "\n",
    "    analysis = cv2.connectedComponentsWithStats(crop_contoured,4,cv2.CV_32S)\n",
    "    (totalLabels, label_ids, values, centroid) = analysis\n",
    "    symbolList = []\n",
    "    xCentroidList = []\n",
    "    \n",
    "    for i in range(1,totalLabels):\n",
    "        \n",
    "        area = values[i, cv2.CC_STAT_AREA] \n",
    "        X,Y = centroid[i]\n",
    "        \n",
    "        if (area < 50) or (area > 1000):\n",
    "            continue\n",
    "            \n",
    "        new_img = crop_contoured.copy()\n",
    "\n",
    "        x1 = values[i, cv2.CC_STAT_LEFT]\n",
    "        y1 = values[i, cv2.CC_STAT_TOP]\n",
    "        w = values[i, cv2.CC_STAT_WIDTH]\n",
    "        h = values[i, cv2.CC_STAT_HEIGHT]\n",
    "\n",
    "        #convert it to 255 value to mark it white\n",
    "        component = (label_ids == i).astype(\"uint8\") * 255\n",
    "\n",
    "        # Increase brightness by multiplying with a scaling factor\n",
    "        brightness_scale = 2  # Adjust this value to increase or decrease brightness\n",
    "        component = component * brightness_scale\n",
    "        cropped_component = component[y1-6:y1+h+6, x1-6:x1+w+6]\n",
    "        #cropped_component = cv2.resize(cropped_component, (15, 15))\n",
    "        #cv2.imshow(\"Individual Component\", cropped_component)\n",
    "        #cv2.waitKey(0)\n",
    "        try:\n",
    "            cv2.imwrite(os.path.join('component' , f'- frame - {frame_count} - component detection.jpg'), cropped_component) #saving crop file in component directory    \n",
    "            cv2.imwrite(os.path.join('crop' , f'frame - {frame_count} - wholeframe.jpg'), crop_contoured)#saving crop file in crop directory\n",
    "            symbol = pytesseract.image_to_string(cropped_component, config='-c tessedit_char_whitelist=0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ --psm 10 --oem 3')\n",
    "            symbol = symbol.replace('\\n', '')\n",
    "            print(symbol)\n",
    "            symbolList.append(symbol)\n",
    "            xCentroidList.append(X)\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "                \n",
    "    print(symbolList)    \n",
    "    xCentroidList, symbolList = zip(*sorted(zip(xCentroidList, symbolList)))\n",
    "    license_plate = ''.join(symbolList)\n",
    "            \n",
    "    return license_plate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3a64c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_frame(frame):\n",
    "    \n",
    "    resultimage = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "     \n",
    "    return resultimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c8983c6",
   "metadata": {},
   "outputs": [],
   "source": [
    " def check_license(license_plate):\n",
    "        \n",
    "    my_url = 'https://check.bgtoll.bg/check/vignette/plate/BG/' + license_plate\n",
    "    x = requests.get(my_url)\n",
    "    if (x.status_code != 200):\n",
    "        result_text = \"error\"\n",
    "        time_left = \"error\"\n",
    "        return result_text, time_left\n",
    "    \n",
    "    p = json.loads(x.content)        \n",
    "    \n",
    "    if (p['vignette'] is None):\n",
    "        result_text = \"Vignette not valid.\"\n",
    "        time_left = \"N/A\"\n",
    "        return result_text,time_left\n",
    "    \n",
    "    result_text = \"Vignette is valid\"\n",
    "    time_left = p['vignette']['validityDateToFormated']\n",
    "    return result_text,time_left\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51ad1dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frameProportions(frame):\n",
    "    a,b = frame.shape\n",
    "    \n",
    "    a_p = a/608\n",
    "    b_p = b/608\n",
    "    \n",
    "    return a_p, b_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b59faf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rectangle(frame,detection):\n",
    "    \n",
    "        data = results.xyxy[0][i]\n",
    "        a = (int(data[0]), int(data[1]))\n",
    "        b = (int(data[2]), int(data[3]))\n",
    "        \n",
    "        cv2.rectangle(frame,a,b,(0,255,0), 3)\n",
    "        \n",
    "        return a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b17cebf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----number of plates detected = 1 - at frame 1--------------\n",
      "checking confidence level of detection - 1 \n",
      "detection's confidence is too low\n",
      "++++end of analysis for detection number++++ 1\n",
      "-----number of plates detected = 1 - at frame 2--------------\n",
      "checking confidence level of detection - 1 \n",
      "detection's confidence is too low\n",
      "++++end of analysis for detection number++++ 1\n",
      "-----number of plates detected = 1 - at frame 3--------------\n",
      "checking confidence level of detection - 1 \n",
      "detection's confidence is too low\n",
      "++++end of analysis for detection number++++ 1\n",
      "-----number of plates detected = 1 - at frame 4--------------\n",
      "checking confidence level of detection - 1 \n",
      "passed the confidence test\n",
      "B\n",
      "\n",
      "9\n",
      "9\n",
      "4\n",
      "K\n",
      "I\n",
      "2\n",
      "\n",
      "['B', '', '9', '9', '4', 'K', 'I', '2', '']\n",
      "KI2994B\n",
      "-----number of plates detected = 2 - at frame 5--------------\n",
      "checking confidence level of detection - 1 \n",
      "passed the confidence test\n",
      "9\n",
      "4\n",
      "B\n",
      "\n",
      "K\n",
      "I\n",
      "2\n",
      "9\n",
      "\n",
      "['9', '4', 'B', '', 'K', 'I', '2', '9', '']\n",
      "KI2994B\n",
      "checking confidence level of detection - 2 \n",
      "detection's confidence is too low\n",
      "++++end of analysis for detection number++++ 2\n",
      "-----number of plates detected = 1 - at frame 6--------------\n",
      "checking confidence level of detection - 1 \n",
      "passed the confidence test\n",
      "9\n",
      "4\n",
      "B\n",
      "\n",
      "K\n",
      "I\n",
      "2\n",
      "9\n",
      "\n",
      "['9', '4', 'B', '', 'K', 'I', '2', '9', '']\n",
      "KI2994B\n"
     ]
    }
   ],
   "source": [
    "#set empty lists\n",
    "crop_index = []\n",
    "number_plate = []\n",
    "date =[]\n",
    "validation_df = []\n",
    "time_remaining_lst = []\n",
    "\n",
    "#define video source\n",
    "video_1 = 'video_test.mp4'\n",
    "\n",
    "\n",
    "#load video\n",
    "cap = cv2.VideoCapture(video_1)\n",
    "frame_count = 1\n",
    "\n",
    "\n",
    "#start video\n",
    "while cap.isOpened():\n",
    "    \n",
    "    \n",
    "    ret, frame = cap.read() #ret is boolean, returns true if frame is available;\n",
    "    frame_resized = cv2.resize(frame, (608, 608)) #resizing the frames for better utilization of YOLO\n",
    "    \n",
    "    results = model(frame_resized) #run YOLO on the resized frame\n",
    "    \n",
    "    print(f'-----number of plates detected = {len((results.xyxy[0]))} - at frame {frame_count}--------------')\n",
    "\n",
    "    #    ---      ---      ---        0  1  2  3  4  5      \n",
    "    #loop through elements in tensor[h1,w1,h2,w2,cf,lb] \n",
    "    for i in range(len(results.xyxy[0])): #len represents the number of tensors;n tensors is the number of detections;#the loop is executed for each tenso\n",
    "                                           \n",
    "        print(f'checking confidence level of detection - {i + 1} ')\n",
    "\n",
    "        conf = results.xyxy[0][i][4] #take the ith tensor/detection ; #conf = data[4] #take the confidence of that detection\n",
    "        \n",
    "        if (conf < 0.80): #checking how confident is the model; not acceptable under 80%\n",
    "            print(\"detection's confidence is too low\")\n",
    "            print(f'++++end of analysis for detection number++++ {i+1}')\n",
    "            continue\n",
    "            \n",
    "        print(f'passed the confidence test')\n",
    "        \n",
    "        draw_rectangle(frame_resized,results.xyxy[0][i])\n",
    "        gray_frame = format_frame(frame)\n",
    "        extraction = get_extraction(gray_frame, results.xyxy[0][i],frame_count)\n",
    "        text_license = extraction[1]\n",
    "        \n",
    "        if text_license == \"N/A\":\n",
    "            continue\n",
    "\n",
    "        #check if plate has already been processed\n",
    "        if (text_license in number_plate):\n",
    "            \n",
    "            print(f'{text_license} is already recorded')\n",
    "            plate_index = number_plate.index(text_license)\n",
    "            #frame_resized = cv2.putText(frame_resized, f\"{validation_df[plate_index]} || {time_remaining_lst[plate_index]}\", (a[0],a[1]-30), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            #1, (255,0,0), 1, cv2.LINE_AA)\n",
    "            continue\n",
    "    \n",
    "        \n",
    "        print('new license plate found')\n",
    "        validation = check_license(text_license) #Validating sticker\n",
    "        vignette_status = validation[0]\n",
    "        time_remaining = validation[1]\n",
    "\n",
    "\n",
    "        #frame_resized = cv2.putText(frame_resized, f\"{vignette_status} || {time_remaining}\", (a[0],a[1]-30), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        #1, (255,0,0), 1, cv2.LINE_AA)\n",
    "        print(f'data for detection number and license plate {i+1} => {text_license} has been collected')\n",
    "\n",
    "        #gathering data\n",
    "        number_plate.append(text_license) # add number_plate\n",
    "        crop_index.append(frame_count) # record frame of detection\n",
    "        date.append(pd.datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")) #record time of detection\n",
    "        validation_df.append(vignette_status) #add vignette status\n",
    "        time_remaining_lst.append(time_remaining) #add remaining time of vignette\n",
    "\n",
    "\n",
    "        print(f'++++end of analysis for detection number {i+1}++++')\n",
    "        \n",
    "    frame_count += 1\n",
    "    \n",
    "    #display frame\n",
    "    cv2.imshow('YOLO', frame_resized)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('s'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "#aggregate data\n",
    "data = list(zip(crop_index,number_plate,date\n",
    "                ,validation_df,time_remaining_lst))\n",
    "df = pd.DataFrame(data,columns = [\"frame\",\"number plate\",\"time of detection\",\"sticker status\",\"time until expiry\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31ceb32c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame</th>\n",
       "      <th>number plate</th>\n",
       "      <th>time of detection</th>\n",
       "      <th>sticker status</th>\n",
       "      <th>time until expiry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [frame, number plate, time of detection, sticker status, time until expiry]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd26822e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absl-py==1.4.0\n",
      "anyio==3.6.2\n",
      "argon2-cffi==21.3.0\n",
      "argon2-cffi-bindings==21.2.0\n",
      "arrow==1.2.3\n",
      "asttokens==2.2.1\n",
      "async-generator==1.10\n",
      "attrs==22.2.0\n",
      "backcall==0.2.0\n",
      "beautifulsoup4==4.11.1\n",
      "bleach==5.0.1\n",
      "cachetools==5.3.0\n",
      "certifi==2022.12.7\n",
      "cffi==1.15.1\n",
      "charset-normalizer==3.1.0\n",
      "chart-studio==1.1.0\n",
      "colorama==0.4.6\n",
      "colorlover==0.3.0\n",
      "comm==0.1.2\n",
      "contourpy==1.0.7\n",
      "cufflinks==0.17.3\n",
      "cycler==0.11.0\n",
      "Cython==0.29.34\n",
      "debugpy==1.6.5\n",
      "decorator==5.1.1\n",
      "defusedxml==0.7.1\n",
      "docopt==0.6.2\n",
      "entrypoints==0.4\n",
      "et-xmlfile==1.1.0\n",
      "exceptiongroup==1.1.1\n",
      "executing==1.2.0\n",
      "fastjsonschema==2.16.2\n",
      "filelock==3.11.0\n",
      "fonttools==4.38.0\n",
      "fqdn==1.5.1\n",
      "gitdb==4.0.10\n",
      "GitPython==3.1.31\n",
      "google-auth==2.17.2\n",
      "google-auth-oauthlib==1.0.0\n",
      "grpcio==1.53.0\n",
      "h11==0.14.0\n",
      "idna==3.4\n",
      "imageio==2.31.0\n",
      "ipykernel==6.20.2\n",
      "ipython==8.8.0\n",
      "ipython-genutils==0.2.0\n",
      "ipywidgets==8.0.4\n",
      "isoduration==20.11.0\n",
      "jedi==0.18.2\n",
      "Jinja2==3.1.2\n",
      "joblib==1.2.0\n",
      "jsonpointer==2.3\n",
      "jsonschema==4.17.3\n",
      "jupyter==1.0.0\n",
      "jupyter-console==6.4.4\n",
      "jupyter-events==0.6.3\n",
      "jupyter_client==7.4.9\n",
      "jupyter_core==5.1.3\n",
      "jupyter_server==2.1.0\n",
      "jupyter_server_terminals==0.4.4\n",
      "jupyterlab-pygments==0.2.2\n",
      "jupyterlab-widgets==3.0.5\n",
      "kiwisolver==1.4.4\n",
      "lazy_loader==0.2\n",
      "Markdown==3.4.3\n",
      "MarkupSafe==2.1.1\n",
      "matplotlib==3.6.3\n",
      "matplotlib-inline==0.1.6\n",
      "mistune==2.0.4\n",
      "mpmath==1.3.0\n",
      "nbclassic==0.4.8\n",
      "nbclient==0.7.2\n",
      "nbconvert==7.2.8\n",
      "nbformat==5.7.3\n",
      "nest-asyncio==1.5.6\n",
      "networkx==3.1\n",
      "notebook==6.5.2\n",
      "notebook_shim==0.2.2\n",
      "numpy==1.24.1\n",
      "oauthlib==3.2.2\n",
      "opencv-contrib-python==4.7.0.72\n",
      "opencv-python==4.7.0.72\n",
      "openpyxl==3.1.2\n",
      "outcome==1.2.0\n",
      "packaging==23.0\n",
      "pandas==1.5.2\n",
      "pandocfilters==1.5.0\n",
      "parso==0.8.3\n",
      "patsy==0.5.3\n",
      "pickleshare==0.7.5\n",
      "Pillow==9.4.0\n",
      "pipreqs==0.4.13\n",
      "platformdirs==2.6.2\n",
      "plotly==5.14.1\n",
      "pmdarima==2.0.3\n",
      "prometheus-client==0.15.0\n",
      "prompt-toolkit==3.0.36\n",
      "protobuf==4.22.1\n",
      "psutil==5.9.4\n",
      "pure-eval==0.2.2\n",
      "pyasn1==0.4.8\n",
      "pyasn1-modules==0.2.8\n",
      "pycparser==2.21\n",
      "Pygments==2.14.0\n",
      "pyparsing==3.0.9\n",
      "pyrsistent==0.19.3\n",
      "PySocks==1.7.1\n",
      "pytesseract==0.3.10\n",
      "python-dateutil==2.8.2\n",
      "python-json-logger==2.0.4\n",
      "pytz==2022.7.1\n",
      "PyWavelets==1.4.1\n",
      "pywin32==305\n",
      "pywinpty==2.0.10\n",
      "PyYAML==6.0\n",
      "pyzmq==25.0.0\n",
      "qtconsole==5.4.0\n",
      "QtPy==2.3.0\n",
      "requests==2.28.2\n",
      "requests-oauthlib==1.3.1\n",
      "retrying==1.3.4\n",
      "rfc3339-validator==0.1.4\n",
      "rfc3986-validator==0.1.1\n",
      "rsa==4.9\n",
      "scikit-image==0.21.0\n",
      "scikit-learn==1.2.0\n",
      "scipy==1.10.0\n",
      "seaborn==0.12.2\n",
      "selenium==4.9.1\n",
      "Send2Trash==1.8.0\n",
      "six==1.16.0\n",
      "smmap==5.0.0\n",
      "sniffio==1.3.0\n",
      "sortedcontainers==2.4.0\n",
      "soupsieve==2.3.2.post1\n",
      "stack-data==0.6.2\n",
      "statsmodels==0.13.5\n",
      "sympy==1.11.1\n",
      "tenacity==8.2.2\n",
      "tensorboard==2.12.1\n",
      "tensorboard-data-server==0.7.0\n",
      "tensorboard-plugin-wit==1.8.1\n",
      "terminado==0.17.1\n",
      "tesseract==0.1.3\n",
      "thop==0.1.1.post2209072238\n",
      "threadpoolctl==3.1.0\n",
      "tifffile==2023.4.12\n",
      "tinycss2==1.2.1\n",
      "torch==2.0.0\n",
      "torchaudio==2.0.1\n",
      "torchvision==0.15.1\n",
      "tornado==6.2\n",
      "tqdm==4.65.0\n",
      "traitlets==5.8.1\n",
      "trio==0.22.0\n",
      "trio-websocket==0.10.2\n",
      "typing_extensions==4.5.0\n",
      "ultralytics==8.0.119\n",
      "uri-template==1.2.0\n",
      "urllib3==1.26.15\n",
      "wcwidth==0.2.6\n",
      "webcolors==1.12\n",
      "webencodings==0.5.1\n",
      "websocket-client==1.4.2\n",
      "Werkzeug==2.2.3\n",
      "widgetsnbextension==4.0.5\n",
      "wsproto==1.2.0\n",
      "yarg==0.1.9\n"
     ]
    }
   ],
   "source": [
    "! pip3 freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13520243",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
